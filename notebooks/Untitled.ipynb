{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2450fc9-055a-4e87-97ae-d61734caf5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8316d31e-2d2e-4450-ac21-fc67e41c4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataloader import ImageNetA, get_dataloader\n",
    "from data.datautils import PatchAugmenter, AugmenterTPT\n",
    "from utils.losses import defaultTPT_loss, patch_loss1, patch_loss2, patch_loss3, patch_loss4\n",
    "from model.custom_clip import get_coop\n",
    "from copy import deepcopy\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06151fca-004b-4375-a912-978f250d9805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = {\n",
    "    \"imagenet_a_path\": \"../../Datasets/imagenet-a/\",\n",
    "    \"coop_weight_path\": \"../../model.pth.tar-50\",\n",
    "    \"n_aug\": 4,\n",
    "    \"n_patches\": 16,\n",
    "    \"batch_size\": 1,\n",
    "    \"arch\": \"RN50\",\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"n_ctx\": 4,\n",
    "    \"ctx_init\": \"\",\n",
    "    \"class_token_position\": \"end\",\n",
    "    \"csc\": False,\n",
    "    \"run_name\": \"\",\n",
    "    \"augmenter\": \"PatchAugmenter\",\n",
    "    \"loss\": \"defaultTPT\",\n",
    "    \"augmix\": True,\n",
    "    \"severity\": 1,\n",
    "    \"num_workers\": 1,\n",
    "    \"save\": False,\n",
    "    \"reduced_size\": None,\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"save_imgs\": False,\n",
    "    \"selection_p_all\": 0.1,\n",
    "    \"selection_p_patch\": 0.9\n",
    "}\n",
    "\n",
    "args = dotdict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5633684-2376-4a65-bc6d-4057de6d04e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "torch.float32\n",
      "Random initialization: initializing a generic context\n",
      "Initial context: \"X X X X\"\n",
      "Number of context words (tokens): 4\n",
      "Use pre-trained soft prompt (CoOp) as initialization\n"
     ]
    }
   ],
   "source": [
    "def parse_augmenter(args):\n",
    "    if args.augmenter == \"AugmenterTPT\":\n",
    "        args.augmenter = AugmenterTPT(args.n_aug, args.augmix, args.severity)\n",
    "    elif args.augmenter == \"PatchAugmenter\":\n",
    "        print(args.n_patches)\n",
    "        args.augmenter = PatchAugmenter(\n",
    "            args.n_aug, args.n_patches, args.augmix, args.severity\n",
    "        )\n",
    "    else:\n",
    "        exit(\"Augmenter not valid\")\n",
    "\n",
    "parse_augmenter(args)\n",
    "device = args.device\n",
    "\n",
    "\n",
    "classnames = ImageNetA.classnames\n",
    "dataset = ImageNetA(args.imagenet_a_path, transform=args.augmenter)\n",
    "args.nclasses = len(classnames)\n",
    "args.classnames = classnames\n",
    "dataloader = get_dataloader(\n",
    "    dataset,\n",
    "    args.batch_size,\n",
    "    shuffle=args.dataset_shuffle,\n",
    "    reduced_size=args.reduced_size,\n",
    "    num_workers=args.num_workers,\n",
    ")\n",
    "model = get_coop(args.arch, classnames, args.device, args.n_ctx, args.ctx_init)\n",
    "\n",
    "print(\"Use pre-trained soft prompt (CoOp) as initialization\")\n",
    "pretrained_ctx = torch.load(args.coop_weight_path)[\"state_dict\"][\"ctx\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.prompt_learner.ctx.copy_(pretrained_ctx)\n",
    "    model.prompt_learner.ctx_init_state = pretrained_ctx\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"prompt_learner\" not in name:\n",
    "        param.requires_grad_(False)\n",
    "\n",
    "model = model.to(args.device)\n",
    "\n",
    "trainable_param = model.prompt_learner.parameters()\n",
    "optimizer = torch.optim.AdamW(trainable_param, args.learning_rate)\n",
    "optim_state = deepcopy(optimizer.state_dict())\n",
    "scaler = torch.cuda.amp.GradScaler(init_scale=1000)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "model.reset_classnames(classnames, args.arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b339f771-b159-41f1-b5be-f4e533048d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c04983-08e3-44f1-a48a-de8ecfd00282",
   "metadata": {},
   "outputs": [],
   "source": [
    "(imgs, target) = first_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd69d8b8-f572-4687-902a-c9b4f5e42427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "images = torch.cat(imgs[1:], dim=0).to(device)  # don't consider view image\n",
    "orig_img = imgs[1].to(device)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acc53984-181e-47d6-bd70-e3c84ded09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(images[5].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52aa2541-61e3-4736-bf19-2ccb36e72619",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        output = model(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0f6169-3d7e-4f95-a198-53940c46ecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor does not contain NaN values.\n"
     ]
    }
   ],
   "source": [
    "if torch.isnan(output).any():\n",
    "    print(\"The tensor contains NaN values.\")\n",
    "    \n",
    "    # Find rows containing NaN\n",
    "    rows_with_nan = torch.any(torch.isnan(output), dim=1)\n",
    "    nan_indices = torch.nonzero(rows_with_nan, as_tuple=True)[0]  # Get indices of rows with NaN\n",
    "    \n",
    "    for idx in nan_indices:\n",
    "        print(f\"Row {idx} contains NaN values:\")\n",
    "        print(output[idx])\n",
    "else:\n",
    "    print(\"The tensor does not contain NaN values.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f650128-0371-43ac-9d56-dd56e32dc79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)\n",
    "\n",
    "print(output[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa528e4-4b3e-4e3e-8c2e-bddbe28775b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)\n",
    "print(torch.isnan(output).any())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5135949b-c1a5-4f16-b0b3-0e49200b5133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 5, 200])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reshape_output_patches(output, args):\n",
    "    return output.view(-1, args.n_aug + 1, output.shape[-1])\n",
    "\n",
    "output_reshaped = reshape_output_patches(output, args)\n",
    "print(torch.isnan(output_reshaped).any())\n",
    "output_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a85df8a-2137-4805-9281-e499fba29636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 200])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_output_per_patch = output_reshaped.mean(dim=1)\n",
    "print(torch.isnan(mean_output_per_patch).any())\n",
    "mean_output_per_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f30393ab-109f-43b2-95a7-a11b22c2ea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 200])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_logprob_per_patch = mean_output_per_patch.log_softmax(dim=1)\n",
    "print(torch.isnan(mean_logprob_per_patch).any())\n",
    "mean_logprob_per_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48058af6-ae9a-485e-ade6-f6fb6a1ba0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n",
      "tensor([-2.2812, -3.4219, -2.6270, -4.1406, -3.7012, -2.7480, -4.1602, -3.0098,\n",
      "        -3.3828, -2.3730, -3.0996, -2.9980, -3.5996, -3.6172, -3.8203, -3.8145,\n",
      "        -4.2344], device='cuda:0', dtype=torch.float16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_per_patch = (mean_logprob_per_patch * torch.exp(mean_logprob_per_patch)).sum(dim=-1)\n",
    "print(torch.isnan(entropy_per_patch).any())\n",
    "print(entropy_per_patch)\n",
    "entropy_per_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5869c08b-d2d2-408f-831f-c77978683080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8828, 3.4727, 4.8555,  ..., 4.0391, 5.4297, 2.3711],\n",
       "        [2.5996, 2.5645, 2.2383,  ..., 3.7461, 1.9814, 1.9727],\n",
       "        [4.4375, 3.3965, 3.1426,  ..., 4.5977, 3.8652, 2.7500],\n",
       "        ...,\n",
       "        [2.5684, 2.0293, 1.8145,  ..., 2.9863, 2.0254, 2.0703],\n",
       "        [2.1309, 2.1094, 1.9580,  ..., 3.2031, 1.9258, 2.1621],\n",
       "        [2.0117, 1.3633, 1.5693,  ..., 2.1836, 1.9102, 1.4551]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 1e-6\n",
    "soft_logprob_output = mean_logprob_per_patch * (1/(entropy_per_patch.unsqueeze(dim=1) + epsilon))\n",
    "soft_logprob_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5090f81e-4f5a-4389-8f18-67b1147239ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 200])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_entropy_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ae9921f-e589-4309-b68e-e02711423c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-13.8125, -12.3125, -12.1250, -10.9844, -11.0781, -16.6250,  -7.4570,\n",
      "        -15.2969, -13.6094, -10.4844, -14.8594, -14.0938, -12.7812, -15.6250,\n",
      "        -12.8125,  -8.4531, -15.6094, -14.1250, -15.9219,  -9.7344, -11.9688,\n",
      "        -10.8594, -13.7500, -15.5469, -14.3281,  -9.6875, -10.3906,  -9.2188,\n",
      "        -15.5781, -15.6094, -10.4219, -12.2656, -11.0000, -12.3594, -15.0000,\n",
      "        -16.7031, -13.9688, -11.9062, -12.5156,  -9.3281, -11.0938, -11.9375,\n",
      "        -10.6406, -10.6406, -12.8281,  -9.7031, -11.0938, -14.4375, -14.3594,\n",
      "        -11.6875, -12.5312, -13.6562, -15.3438, -12.8750, -13.2656, -12.3906,\n",
      "        -12.2969, -12.3750, -18.0781, -16.3750, -10.1250, -15.7344,  -8.9062,\n",
      "        -13.6406, -15.9531, -11.4531, -10.7656, -15.2500,  -8.4375, -12.5312,\n",
      "        -10.9688,  -8.2500,  -7.7539,  -9.2500, -10.5000,  -8.2812,  -9.2188,\n",
      "        -17.4844, -15.6719, -11.3906,  -7.3945, -19.2031, -10.0781, -15.5469,\n",
      "         -8.2188, -11.4219, -12.1875, -14.2969, -16.1875, -11.8594, -19.0625,\n",
      "        -13.6406, -16.8906, -16.3281, -13.9531, -17.6719, -11.2969, -16.6719,\n",
      "        -15.5625, -17.6406,  -1.1279, -14.7812, -13.7031, -17.9062, -20.8281,\n",
      "         -9.7344, -19.7188, -14.5781, -15.3750,  -5.4727, -13.2969, -11.4844,\n",
      "        -12.5781, -13.9062, -12.7031, -12.2656, -15.3906, -16.8750, -13.9062,\n",
      "        -18.5000, -10.2031, -18.5938,  -7.0195, -20.5625, -16.7031, -10.5469,\n",
      "        -13.4062, -10.5938,  -9.5469, -14.4531,  -6.7852, -23.1094, -13.8281,\n",
      "        -16.7188, -12.9844,  -6.8008, -20.5312, -11.7031, -19.7344, -17.3438,\n",
      "        -19.9688, -18.5312, -21.9844, -17.0625, -10.0625,  -8.0312, -15.5625,\n",
      "        -15.5938, -16.5000, -16.3125, -13.8750, -16.9688, -14.7656, -13.4062,\n",
      "        -12.5312, -11.9531, -12.6875, -17.7656, -14.1719, -15.2031, -16.0781,\n",
      "        -16.8125, -19.7656, -14.7188, -10.9375, -18.2969, -18.4219, -11.2812,\n",
      "        -18.3438, -15.8906,  -8.1719, -12.5312,  -7.7070,  -8.7969,  -6.6133,\n",
      "        -15.7188,  -9.4375, -16.2031, -16.5312, -10.1094,  -8.8125, -12.5000,\n",
      "        -13.5781,  -7.2852, -12.4844, -11.2969,  -8.8906, -12.8281, -13.3281,\n",
      "         -4.3164,  -2.5352,  -9.2812, -13.8438, -11.9062,  -9.4688, -14.0312,\n",
      "         -9.1406,  -0.5659,  -9.1719, -12.3125], device='cuda:0',\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprob_output = soft_entropy_loss.mean(dim=0).log_softmax(dim=0)\n",
    "print(logprob_output)\n",
    "logprob_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2df4b451-50e4-4aae-8b8b-80ed89839e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0596, device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_loss = -(logprob_output * torch.exp(logprob_output)).sum(dim=0)\n",
    "entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70315958-84f4-42c4-893f-f4c231705ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [2, 3],\n",
      "        [3, 4]])\n",
      "tensor([4, 5, 6])\n",
      "tensor([[ 4,  8],\n",
      "        [10, 15],\n",
      "        [18, 24]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [2, 3], [3, 4]])\n",
    "b = torch.tensor([4,5,6])\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(a*b.unsqueeze(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c847a379-2a40-4e7d-a867-4bfd7cd5750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_loss5(outputs, args):\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    output_reshaped = reshape_output_patches(output, args)\n",
    "    mean_output_per_patch = output_reshaped.mean(dim=1)\n",
    "\n",
    "    mean_logprob_per_patch = mean_output_per_patch.log_softmax(dim=1)\n",
    "    entropy_per_patch = -(mean_logprob_per_patch * torch.exp(mean_logprob_per_patch)).sum(dim=-1)\n",
    "\n",
    "    weighted_logprob_per_patch = mean_logprob_per_patch * (1/(entropy_per_patch.unsqueeze(dim=1) + epsilon))\n",
    "    logprob_output = weighted_logprob_per_patch.mean(dim=0).log_softmax(dim=0)\n",
    "\n",
    "    entropy_loss = -(logprob_output * torch.exp(logprob_output)).sum(dim=0)\n",
    "\n",
    "    return entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d15044-b1bf-4a44-b6dd-913dd95881c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
