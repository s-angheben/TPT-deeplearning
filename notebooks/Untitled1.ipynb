{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cde3bd9-f862-4ea1-ab0c-695eebd63d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a753c71a-47af-4754-a352-8ff493b3945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--imagenet_a_path IMAGENET_A_PATH]\n",
      "                             [--coop_weight_path COOP_WEIGHT_PATH]\n",
      "                             [--n_aug N_AUG] [--n_patches N_PATCHES]\n",
      "                             [--batch_size BATCH_SIZE] [--arch ARCH]\n",
      "                             [--device DEVICE] [--learning_rate LEARNING_RATE]\n",
      "                             [--n_ctx N_CTX] [--ctx_init CTX_INIT]\n",
      "                             [--class_token_position CLASS_TOKEN_POSITION]\n",
      "                             [--csc] [--run_name RUN_NAME]\n",
      "                             [--augmenter AUGMENTER] [--loss LOSS] [--augmix]\n",
      "                             [--no-augmix] [--severity SEVERITY]\n",
      "                             [--num_workers NUM_WORKERS] [--save] [--no-save]\n",
      "                             [--reduced_size REDUCED_SIZE] [--dataset_shuffle]\n",
      "                             [--no-dataset_shuffle] [--save_imgs]\n",
      "                             [--no-save_imgs]\n",
      "                             [--selection_p_all SELECTION_P_ALL]\n",
      "                             [--selection_p_patch SELECTION_P_PATCH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/sam/.local/share/jupyter/runtime/kernel-b71f5672-9bfe-4abe-8a5c-095db20eaf4d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "from data.dataloader import ImageNetA, get_dataloader\n",
    "from data.datautils import AugmenterTPT, PatchAugmenter\n",
    "from model.custom_clip import get_coop\n",
    "from utils.utils import set_random_seed, MetricsTracker\n",
    "from utils.losses import (\n",
    "    defaultTPT_loss,\n",
    "    patch_loss1,\n",
    "    patch_loss2,\n",
    "    patch_loss3,\n",
    "    patch_loss4,\n",
    ")\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "def test_time_tuning(model, inputs, optimizer, scaler, args, tta_step=1):\n",
    "    for _ in range(tta_step):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(inputs)\n",
    "            loss = args.loss(output, args)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # compute gradient and do SGD step\n",
    "        scaler.scale(loss).backward()\n",
    "        # Unscales the gradients of optimizer's assigned params in-place\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def test_time_adapt_eval(\n",
    "    dataloader, model, optimizer, optim_state, scaler, writer, device, args\n",
    "):\n",
    "    metrics = MetricsTracker(args)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model.reset()\n",
    "\n",
    "    print(\"Test Time Evaluation\")\n",
    "\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (imgs, target) in progress_bar:\n",
    "        view_img = imgs[0]\n",
    "        images = torch.cat(imgs[1:], dim=0).to(device)  # don't consider view image\n",
    "        orig_img = imgs[1].to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.reset()\n",
    "        optimizer.load_state_dict(optim_state)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output_base = model(orig_img)\n",
    "\n",
    "        test_time_tuning(model, images, optimizer, scaler, args)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output_tpt = model(orig_img)\n",
    "\n",
    "        metrics.update(i, view_img, output_base, output_tpt, target, writer, args)\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"Base Acc\": f\"{metrics.get_accuracy_base():.2f}%\",\n",
    "                \"TPT Acc\": f\"{metrics.get_accuracy_tpt():.2f}%\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    metrics.write_info(writer, args)\n",
    "\n",
    "    return metrics.get_accuracy_tpt()\n",
    "\n",
    "\n",
    "def generate_run_name(args):\n",
    "    if args.save:\n",
    "        config_name = f\"size={args.reduced_size if args.reduced_size else 'Full'}_augmenter={args.augmenter}_loss={args.loss}_naug={args.n_aug}_npatch={args.n_patches}_augmix={args.augmix}_severity={args.severity}_lr={args.learning_rate}_spall={args.selection_p_all}_sppat={args.selection_p_patch}\"\n",
    "        return f\"{args.run_name}_{config_name}\" if args.run_name else f\"{config_name}\"\n",
    "    else:\n",
    "        return \"tmp\"\n",
    "\n",
    "\n",
    "### COMPATIBILITY (augmenter - loss)\n",
    "## AugmenterTPT - defaultTPT, patch_loss1, patch_loss2, patch_loss3, patch_loss4\n",
    "\n",
    "\n",
    "def parse_loss(args):\n",
    "    if args.loss == \"defaultTPT\":\n",
    "        args.loss = defaultTPT_loss\n",
    "    elif args.loss == \"patch_loss1\":\n",
    "        args.loss = patch_loss1\n",
    "    elif args.loss == \"patch_loss2\":\n",
    "        args.loss = patch_loss2\n",
    "    elif args.loss == \"patch_loss3\":\n",
    "        args.loss = patch_loss3\n",
    "    elif args.loss == \"patch_loss4\":\n",
    "        args.loss = patch_loss4\n",
    "    else:\n",
    "        exit(\"Loss not valid\")\n",
    "\n",
    "\n",
    "def parse_augmenter(args):\n",
    "    if args.augmenter == \"AugmenterTPT\":\n",
    "        args.augmenter = AugmenterTPT(args.n_aug, args.augmix, args.severity)\n",
    "    elif args.augmenter == \"PatchAugmenter\":\n",
    "        args.augmenter = PatchAugmenter(\n",
    "            args.n_aug, args.n_patches, args.augmix, args.severity\n",
    "        )\n",
    "    else:\n",
    "        exit(\"Augmenter not valid\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parser.parse_args()\n",
    "    run_name = generate_run_name(args)\n",
    "\n",
    "    print(\"Config:\", json.dumps(vars(args), indent=4))\n",
    "\n",
    "    writer = SummaryWriter(log_dir=f\"runs/{run_name}\")\n",
    "    writer.add_text(\"Config\", json.dumps(vars(args), indent=4))\n",
    "    parse_augmenter(args)\n",
    "    parse_loss(args)\n",
    "\n",
    "    set_random_seed(1234)\n",
    "\n",
    "    classnames = ImageNetA.classnames\n",
    "    dataset = ImageNetA(args.imagenet_a_path, transform=args.augmenter)\n",
    "    args.nclasses = len(classnames)\n",
    "    args.classnames = classnames\n",
    "    dataloader = get_dataloader(\n",
    "        dataset,\n",
    "        args.batch_size,\n",
    "        shuffle=args.dataset_shuffle,\n",
    "        reduced_size=args.reduced_size,\n",
    "        num_workers=args.num_workers,\n",
    "    )\n",
    "    model = get_coop(args.arch, classnames, args.device, args.n_ctx, args.ctx_init)\n",
    "\n",
    "    print(\"Use pre-trained soft prompt (CoOp) as initialization\")\n",
    "    pretrained_ctx = torch.load(args.coop_weight_path)[\"state_dict\"][\"ctx\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.prompt_learner.ctx.copy_(pretrained_ctx)\n",
    "        model.prompt_learner.ctx_init_state = pretrained_ctx\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"prompt_learner\" not in name:\n",
    "            param.requires_grad_(False)\n",
    "\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    trainable_param = model.prompt_learner.parameters()\n",
    "    optimizer = torch.optim.AdamW(trainable_param, args.learning_rate)\n",
    "    optim_state = deepcopy(optimizer.state_dict())\n",
    "    scaler = torch.cuda.amp.GradScaler(init_scale=1000)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    model.reset_classnames(classnames, args.arch)\n",
    "\n",
    "    result = test_time_adapt_eval(\n",
    "        dataloader, model, optimizer, optim_state, scaler, writer, args.device, args\n",
    "    )\n",
    "\n",
    "    print(result)\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"TPT-deeplearning, coop and TPT-next\")\n",
    "    parser.add_argument(\n",
    "        \"--imagenet_a_path\",\n",
    "        type=str,\n",
    "        default=\"../../Datasets/imagenet-a/\",\n",
    "        help=\"Path to ImageNet-A dataset\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--coop_weight_path\",\n",
    "        type=str,\n",
    "        default=\"../../model.pth.tar-50\",\n",
    "        help=\"Path to pre-trained CoOp weights\",\n",
    "    )\n",
    "    parser.add_argument(\"--n_aug\", type=int, default=63, help=\"Number of augmentations\")\n",
    "    parser.add_argument(\n",
    "        \"--n_patches\",\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"Number of patches for patch augmenter\",\n",
    "    )\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=1, help=\"Batch size\")\n",
    "    parser.add_argument(\"--arch\", type=str, default=\"RN50\", help=\"Model architecture\")\n",
    "    parser.add_argument(\n",
    "        \"--device\",\n",
    "        type=str,\n",
    "        default=\"cuda:0\",\n",
    "        help=\"Device to use, e.g., 'cuda:0' or 'cpu'\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\", type=float, default=5e-3, help=\"Learning rate\"\n",
    "    )\n",
    "    parser.add_argument(\"--n_ctx\", type=int, default=4, help=\"Number of context tokens\")\n",
    "    parser.add_argument(\n",
    "        \"--ctx_init\", type=str, default=\"\", help=\"Context token initialization\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--class_token_position\",\n",
    "        type=str,\n",
    "        default=\"end\",\n",
    "        help=\"Class token position ('end' or 'start')\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--csc\", action=\"store_true\", help=\"Enable class-specific context (CSC)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--run_name\", type=str, default=\"\", help=\"Custom name for TensorBoard run\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--augmenter\",\n",
    "        type=str,\n",
    "        default=\"AugmenterTPT\",\n",
    "        help=\"Select the agumenter: AugmenterTPT, PatchAugmenter\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--loss\",\n",
    "        type=str,\n",
    "        default=\"defaultTPT\",\n",
    "        help=\"Select the loss: defaultTPT, patch_loss1, patch_loss2, patch_loss3, patch_loss4\",\n",
    "    )\n",
    "    parser.add_argument(\"--augmix\", action=\"store_true\", help=\"Enable augmix\")\n",
    "    parser.add_argument(\n",
    "        \"--no-augmix\", action=\"store_false\", dest=\"augmix\", help=\"Disable augmix\"\n",
    "    )\n",
    "    parser.add_argument(\"--severity\", type=int, default=1, help=\"Augmix severity\")\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=1, help=\"number of workers\")\n",
    "    parser.add_argument(\n",
    "        \"--save\", action=\"store_true\", help=\"Enable save to TensorBoard\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-save\",\n",
    "        action=\"store_false\",\n",
    "        dest=\"save\",\n",
    "        help=\"Disable save to TensorBoard\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--reduced_size\", type=int, default=None, help=\"number of data sample\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dataset_shuffle\", action=\"store_true\", help=\"Shuffle the dataset\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-dataset_shuffle\",\n",
    "        action=\"store_false\",\n",
    "        dest=\"dataset_shuffle\",\n",
    "        help=\"Don't shuffle the dataset\",\n",
    "    )\n",
    "    parser.add_argument(\"--save_imgs\", action=\"store_true\", help=\"Enable saving images\")\n",
    "    parser.add_argument(\n",
    "        \"--no-save_imgs\",\n",
    "        action=\"store_false\",\n",
    "        dest=\"save_imgs\",\n",
    "        help=\"Disable saving images\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--selection_p_all\", type=float, default=0.1, help=\"Learning rate\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--selection_p_patch\", type=float, default=0.9, help=\"Learning rate\"\n",
    "    )\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0629c4-d8bc-439a-babc-7ad72c5d78d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
