{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2450fc9-055a-4e87-97ae-d61734caf5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8316d31e-2d2e-4450-ac21-fc67e41c4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataloader import ImageNetA, get_dataloader\n",
    "from data.datautils import PatchAugmenter, AugmenterTPT\n",
    "from utils.losses import defaultTPT_loss, patch_loss1, patch_loss2, patch_loss3, patch_loss4\n",
    "from model.custom_clip import get_coop\n",
    "from copy import deepcopy\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06151fca-004b-4375-a912-978f250d9805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = {\n",
    "    \"imagenet_a_path\": \"../../Datasets/imagenet-a/\",\n",
    "    \"coop_weight_path\": \"../../model.pth.tar-50\",\n",
    "    \"n_aug\": 4,\n",
    "    \"n_patches\": 16,\n",
    "    \"batch_size\": 1,\n",
    "    \"arch\": \"RN50\",\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"n_ctx\": 4,\n",
    "    \"ctx_init\": \"\",\n",
    "    \"class_token_position\": \"end\",\n",
    "    \"csc\": False,\n",
    "    \"run_name\": \"\",\n",
    "    \"augmenter\": \"PatchAugmenter\",\n",
    "    \"loss\": \"defaultTPT\",\n",
    "    \"augmix\": True,\n",
    "    \"severity\": 1,\n",
    "    \"num_workers\": 1,\n",
    "    \"save\": False,\n",
    "    \"reduced_size\": None,\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"save_imgs\": False,\n",
    "    \"selection_p_all\": 0.1,\n",
    "    \"selection_p_patch\": 0.9\n",
    "}\n",
    "\n",
    "args = dotdict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5633684-2376-4a65-bc6d-4057de6d04e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "torch.float32\n",
      "Random initialization: initializing a generic context\n",
      "Initial context: \"X X X X\"\n",
      "Number of context words (tokens): 4\n",
      "Use pre-trained soft prompt (CoOp) as initialization\n"
     ]
    }
   ],
   "source": [
    "def parse_augmenter(args):\n",
    "    if args.augmenter == \"AugmenterTPT\":\n",
    "        args.augmenter = AugmenterTPT(args.n_aug, args.augmix, args.severity)\n",
    "    elif args.augmenter == \"PatchAugmenter\":\n",
    "        print(args.n_patches)\n",
    "        args.augmenter = PatchAugmenter(\n",
    "            args.n_aug, args.n_patches, args.augmix, args.severity\n",
    "        )\n",
    "    else:\n",
    "        exit(\"Augmenter not valid\")\n",
    "\n",
    "parse_augmenter(args)\n",
    "device = args.device\n",
    "\n",
    "\n",
    "classnames = ImageNetA.classnames\n",
    "dataset = ImageNetA(args.imagenet_a_path, transform=args.augmenter)\n",
    "args.nclasses = len(classnames)\n",
    "args.classnames = classnames\n",
    "dataloader = get_dataloader(\n",
    "    dataset,\n",
    "    args.batch_size,\n",
    "    shuffle=args.dataset_shuffle,\n",
    "    reduced_size=args.reduced_size,\n",
    "    num_workers=args.num_workers,\n",
    ")\n",
    "model = get_coop(args.arch, classnames, args.device, args.n_ctx, args.ctx_init)\n",
    "\n",
    "print(\"Use pre-trained soft prompt (CoOp) as initialization\")\n",
    "pretrained_ctx = torch.load(args.coop_weight_path)[\"state_dict\"][\"ctx\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.prompt_learner.ctx.copy_(pretrained_ctx)\n",
    "    model.prompt_learner.ctx_init_state = pretrained_ctx\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"prompt_learner\" not in name:\n",
    "        param.requires_grad_(False)\n",
    "\n",
    "model = model.to(args.device)\n",
    "\n",
    "trainable_param = model.prompt_learner.parameters()\n",
    "optimizer = torch.optim.AdamW(trainable_param, args.learning_rate)\n",
    "optim_state = deepcopy(optimizer.state_dict())\n",
    "scaler = torch.cuda.amp.GradScaler(init_scale=1000)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "model.reset_classnames(classnames, args.arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b339f771-b159-41f1-b5be-f4e533048d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c04983-08e3-44f1-a48a-de8ecfd00282",
   "metadata": {},
   "outputs": [],
   "source": [
    "(imgs, target) = first_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd69d8b8-f572-4687-902a-c9b4f5e42427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "images = torch.cat(imgs[1:], dim=0).to(device)  # don't consider view image\n",
    "orig_img = imgs[1].to(device)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acc53984-181e-47d6-bd70-e3c84ded09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(images[5].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52aa2541-61e3-4736-bf19-2ccb36e72619",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        output = model(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2782eb-fd64-4966-84f0-8b7c7e81c1c5",
   "metadata": {},
   "source": [
    "# TEST1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0f6169-3d7e-4f95-a198-53940c46ecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor does not contain NaN values.\n"
     ]
    }
   ],
   "source": [
    "if torch.isnan(output).any():\n",
    "    print(\"The tensor contains NaN values.\")\n",
    "    \n",
    "    # Find rows containing NaN\n",
    "    rows_with_nan = torch.any(torch.isnan(output), dim=1)\n",
    "    nan_indices = torch.nonzero(rows_with_nan, as_tuple=True)[0]  # Get indices of rows with NaN\n",
    "    \n",
    "    for idx in nan_indices:\n",
    "        print(f\"Row {idx} contains NaN values:\")\n",
    "        print(output[idx])\n",
    "else:\n",
    "    print(\"The tensor does not contain NaN values.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f650128-0371-43ac-9d56-dd56e32dc79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)\n",
    "\n",
    "print(output[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa528e4-4b3e-4e3e-8c2e-bddbe28775b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)\n",
    "print(torch.isnan(output).any())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5135949b-c1a5-4f16-b0b3-0e49200b5133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 5, 200])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reshape_output_patches(output, args):\n",
    "    return output.view(-1, args.n_aug + 1, output.shape[-1])\n",
    "\n",
    "output_reshaped = reshape_output_patches(output, args)\n",
    "print(torch.isnan(output_reshaped).any())\n",
    "output_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a85df8a-2137-4805-9281-e499fba29636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 200])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_output_per_patch = output_reshaped.mean(dim=1)\n",
    "print(torch.isnan(mean_output_per_patch).any())\n",
    "mean_output_per_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f30393ab-109f-43b2-95a7-a11b22c2ea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 200])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_logprob_per_patch = mean_output_per_patch.log_softmax(dim=1)\n",
    "print(torch.isnan(mean_logprob_per_patch).any())\n",
    "mean_logprob_per_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48058af6-ae9a-485e-ade6-f6fb6a1ba0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n",
      "tensor([-2.2812, -3.4219, -2.6270, -4.1406, -3.7012, -2.7480, -4.1602, -3.0098,\n",
      "        -3.3828, -2.3730, -3.0996, -2.9980, -3.5996, -3.6172, -3.8203, -3.8145,\n",
      "        -4.2344], device='cuda:0', dtype=torch.float16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_per_patch = (mean_logprob_per_patch * torch.exp(mean_logprob_per_patch)).sum(dim=-1)\n",
    "print(torch.isnan(entropy_per_patch).any())\n",
    "print(entropy_per_patch)\n",
    "entropy_per_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5869c08b-d2d2-408f-831f-c77978683080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8828, 3.4727, 4.8555,  ..., 4.0391, 5.4297, 2.3711],\n",
       "        [2.5996, 2.5645, 2.2383,  ..., 3.7461, 1.9814, 1.9727],\n",
       "        [4.4375, 3.3965, 3.1426,  ..., 4.5977, 3.8652, 2.7500],\n",
       "        ...,\n",
       "        [2.5684, 2.0293, 1.8145,  ..., 2.9863, 2.0254, 2.0703],\n",
       "        [2.1309, 2.1094, 1.9580,  ..., 3.2031, 1.9258, 2.1621],\n",
       "        [2.0117, 1.3633, 1.5693,  ..., 2.1836, 1.9102, 1.4551]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 1e-6\n",
    "soft_logprob_output = mean_logprob_per_patch * (1/(entropy_per_patch.unsqueeze(dim=1) + epsilon))\n",
    "soft_logprob_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5090f81e-4f5a-4389-8f18-67b1147239ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 200])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_entropy_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ae9921f-e589-4309-b68e-e02711423c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-13.8125, -12.3125, -12.1250, -10.9844, -11.0781, -16.6250,  -7.4570,\n",
      "        -15.2969, -13.6094, -10.4844, -14.8594, -14.0938, -12.7812, -15.6250,\n",
      "        -12.8125,  -8.4531, -15.6094, -14.1250, -15.9219,  -9.7344, -11.9688,\n",
      "        -10.8594, -13.7500, -15.5469, -14.3281,  -9.6875, -10.3906,  -9.2188,\n",
      "        -15.5781, -15.6094, -10.4219, -12.2656, -11.0000, -12.3594, -15.0000,\n",
      "        -16.7031, -13.9688, -11.9062, -12.5156,  -9.3281, -11.0938, -11.9375,\n",
      "        -10.6406, -10.6406, -12.8281,  -9.7031, -11.0938, -14.4375, -14.3594,\n",
      "        -11.6875, -12.5312, -13.6562, -15.3438, -12.8750, -13.2656, -12.3906,\n",
      "        -12.2969, -12.3750, -18.0781, -16.3750, -10.1250, -15.7344,  -8.9062,\n",
      "        -13.6406, -15.9531, -11.4531, -10.7656, -15.2500,  -8.4375, -12.5312,\n",
      "        -10.9688,  -8.2500,  -7.7539,  -9.2500, -10.5000,  -8.2812,  -9.2188,\n",
      "        -17.4844, -15.6719, -11.3906,  -7.3945, -19.2031, -10.0781, -15.5469,\n",
      "         -8.2188, -11.4219, -12.1875, -14.2969, -16.1875, -11.8594, -19.0625,\n",
      "        -13.6406, -16.8906, -16.3281, -13.9531, -17.6719, -11.2969, -16.6719,\n",
      "        -15.5625, -17.6406,  -1.1279, -14.7812, -13.7031, -17.9062, -20.8281,\n",
      "         -9.7344, -19.7188, -14.5781, -15.3750,  -5.4727, -13.2969, -11.4844,\n",
      "        -12.5781, -13.9062, -12.7031, -12.2656, -15.3906, -16.8750, -13.9062,\n",
      "        -18.5000, -10.2031, -18.5938,  -7.0195, -20.5625, -16.7031, -10.5469,\n",
      "        -13.4062, -10.5938,  -9.5469, -14.4531,  -6.7852, -23.1094, -13.8281,\n",
      "        -16.7188, -12.9844,  -6.8008, -20.5312, -11.7031, -19.7344, -17.3438,\n",
      "        -19.9688, -18.5312, -21.9844, -17.0625, -10.0625,  -8.0312, -15.5625,\n",
      "        -15.5938, -16.5000, -16.3125, -13.8750, -16.9688, -14.7656, -13.4062,\n",
      "        -12.5312, -11.9531, -12.6875, -17.7656, -14.1719, -15.2031, -16.0781,\n",
      "        -16.8125, -19.7656, -14.7188, -10.9375, -18.2969, -18.4219, -11.2812,\n",
      "        -18.3438, -15.8906,  -8.1719, -12.5312,  -7.7070,  -8.7969,  -6.6133,\n",
      "        -15.7188,  -9.4375, -16.2031, -16.5312, -10.1094,  -8.8125, -12.5000,\n",
      "        -13.5781,  -7.2852, -12.4844, -11.2969,  -8.8906, -12.8281, -13.3281,\n",
      "         -4.3164,  -2.5352,  -9.2812, -13.8438, -11.9062,  -9.4688, -14.0312,\n",
      "         -9.1406,  -0.5659,  -9.1719, -12.3125], device='cuda:0',\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprob_output = soft_entropy_loss.mean(dim=0).log_softmax(dim=0)\n",
    "print(logprob_output)\n",
    "logprob_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2df4b451-50e4-4aae-8b8b-80ed89839e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0596, device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_loss = -(logprob_output * torch.exp(logprob_output)).sum(dim=0)\n",
    "entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70315958-84f4-42c4-893f-f4c231705ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [2, 3],\n",
      "        [3, 4]])\n",
      "tensor([4, 5, 6])\n",
      "tensor([[ 4,  8],\n",
      "        [10, 15],\n",
      "        [18, 24]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [2, 3], [3, 4]])\n",
    "b = torch.tensor([4,5,6])\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(a*b.unsqueeze(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c847a379-2a40-4e7d-a867-4bfd7cd5750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_loss5(outputs, args):\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    output_reshaped = reshape_output_patches(output, args)\n",
    "    mean_output_per_patch = output_reshaped.mean(dim=1)\n",
    "\n",
    "    mean_logprob_per_patch = mean_output_per_patch.log_softmax(dim=1)\n",
    "    entropy_per_patch = -(mean_logprob_per_patch * torch.exp(mean_logprob_per_patch)).sum(dim=-1)\n",
    "\n",
    "    weighted_logprob_per_patch = mean_logprob_per_patch * (1/(entropy_per_patch.unsqueeze(dim=1) + epsilon))\n",
    "    logprob_output = weighted_logprob_per_patch.mean(dim=0).log_softmax(dim=0)\n",
    "\n",
    "    entropy_loss = -(logprob_output * torch.exp(logprob_output)).sum(dim=0)\n",
    "\n",
    "    return entropy_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd1f79-2889-4217-853e-b0ee76f54940",
   "metadata": {},
   "source": [
    "# TEST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a58ba13e-d0f2-49c9-8131-5aeb3f7a58a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85, 200])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5a44f32-5a6d-483e-b0b3-4853208db8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0779e-01, 3.2997e-04, 1.3947e-05, 2.3210e-04, 2.2471e-05, 5.3345e-02,\n",
       "        3.4046e-04, 4.0512e-03, 3.2349e-02, 1.6365e-03, 3.8643e-03, 1.7147e-03,\n",
       "        3.8576e-04, 1.1719e-02, 9.2328e-05, 3.8576e-04, 3.8266e-04, 7.5340e-05,\n",
       "        7.7128e-05, 1.4067e-05, 1.8072e-04, 2.0921e-05, 1.3709e-05, 4.7340e-03,\n",
       "        2.7847e-03, 5.0306e-04, 1.0242e-03, 3.1734e-04, 2.9465e-02, 3.9864e-03,\n",
       "        1.1978e-03, 1.1719e-02, 4.4394e-04, 9.9277e-04, 1.4587e-02, 1.0025e-02,\n",
       "        5.4512e-03, 3.7551e-06, 5.2631e-05, 4.4644e-05, 2.2113e-05, 5.1796e-05,\n",
       "        3.0756e-04, 5.1260e-06, 4.5085e-04, 8.3590e-04, 1.5612e-03, 3.2539e-03,\n",
       "        5.0306e-04, 1.9848e-04, 3.5405e-04, 1.0222e-04, 2.5105e-04, 3.1972e-04,\n",
       "        7.0381e-04, 6.4087e-04, 5.2738e-04, 1.3971e-04, 1.1009e-02, 5.4407e-04,\n",
       "        1.3125e-04, 2.3079e-03, 9.7513e-05, 1.1835e-01, 6.7532e-05, 1.6272e-05,\n",
       "        2.9504e-05, 4.3793e-03, 1.2474e-02, 4.2915e-06, 7.8976e-05, 2.8896e-04,\n",
       "        1.4603e-05, 6.6137e-04, 1.5135e-03, 1.7881e-06, 7.1526e-07, 9.8348e-06,\n",
       "        1.4439e-03, 7.5936e-05, 2.1458e-06, 1.4079e-04, 8.7595e-04, 1.8179e-05,\n",
       "        1.9550e-04, 1.2040e-04, 2.9266e-05, 5.3549e-04, 5.7340e-05, 8.2135e-05,\n",
       "        4.0102e-04, 2.1398e-05, 4.6897e-04, 1.6332e-04, 9.8944e-06, 1.4816e-02,\n",
       "        5.3673e-03, 3.3379e-06, 2.2852e-04, 2.1303e-04, 1.9073e-06, 1.1313e-04,\n",
       "        1.2326e-04, 3.8803e-05, 7.4911e-04, 4.4644e-05, 3.9482e-04, 1.1921e-05,\n",
       "        3.4833e-04, 5.0664e-06, 8.7595e-04, 1.7881e-06, 2.0046e-03, 9.6738e-05,\n",
       "        1.6570e-05, 6.9141e-06, 3.9995e-05, 2.3246e-06, 1.5438e-05, 8.8811e-05,\n",
       "        3.6180e-05, 1.9848e-04, 2.9206e-06, 1.2136e-04, 1.3328e-04, 1.7941e-04,\n",
       "        1.3709e-05, 1.0729e-06, 2.3723e-05, 5.4407e-04, 2.4676e-05, 4.4394e-04,\n",
       "        6.0225e-04, 1.9741e-03, 1.0133e-06, 1.5342e-04, 1.3781e-03, 3.6716e-05,\n",
       "        1.0383e-04, 6.0081e-05, 1.7524e-04, 1.1425e-03, 1.4639e-04, 1.5700e-04,\n",
       "        4.4703e-06, 1.8597e-05, 2.2829e-05, 7.5340e-05, 7.7128e-05, 9.9838e-05,\n",
       "        4.8375e-04, 2.6226e-05, 1.2136e-04, 3.7611e-05, 4.2260e-05, 8.3387e-05,\n",
       "        6.1393e-06, 1.0967e-05, 4.8103e-03, 1.1086e-05, 5.1260e-06, 2.9206e-06,\n",
       "        1.4906e-03, 3.2043e-03, 6.3086e-04, 6.4433e-05, 3.4103e-03, 1.0461e-04,\n",
       "        6.0558e-05, 5.0306e-04, 3.1590e-06, 2.2674e-04, 8.9407e-07, 9.6560e-06,\n",
       "        9.2983e-06, 1.5318e-05, 1.8060e-05, 1.6451e-05, 4.4678e-01, 1.4186e-05,\n",
       "        3.8505e-05, 8.4698e-05, 4.0352e-05, 5.6446e-05, 1.4484e-05, 4.9055e-05,\n",
       "        2.2495e-04, 7.0000e-03, 9.7752e-04, 5.5552e-05, 2.2829e-05, 3.4571e-06,\n",
       "        6.7186e-04, 7.6866e-03, 7.8087e-03, 2.7955e-05, 1.3971e-04, 1.1051e-04,\n",
       "        4.7684e-06, 5.9853e-03], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_img_output = output[0].softmax(dim=0)\n",
    "orig_img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec0b382d-b775-4eba-a0aa-08681aeb255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.losses import select_confident_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "339f2488-8135-4d91-a7d8-cc9f4f87e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_output = select_confident_samples(output[1:], args.selection_p_all)\n",
    "target_dist = best_output.mean(dim=0).softmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a2fb7c4-e3f5-4a1d-af4e-fb5566102e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.1289, device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.CrossEntropyLoss()(orig_img_output, target_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efc7e9ed-7521-416e-9a36-eac88b199f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = torch.argmax(target_dist)\n",
    "\n",
    "# Create a tensor with zeros, keeping only the maximum element\n",
    "result = torch.zeros_like(target_dist)\n",
    "result[max_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0ebed4e-c673-409d-8ae9-9501c6a52785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795778b-7440-4f62-970e-b6f050ea3e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6295032-a513-43b4-b419-bb441db5b257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original distribution: tensor([0.1000, 0.0500, 0.2000, 0.3000, 0.2500, 0.0500, 0.0500])\n",
      "Filtered and scaled distribution: tensor([0.1111, 0.0000, 0.2222, 0.3333, 0.2778, 0.0000, 0.0556])\n"
     ]
    }
   ],
   "source": [
    "# Example tensor: a distribution over classes\n",
    "output_dist = torch.tensor([0.1, 0.05, 0.2, 0.3, 0.25, 0.05, 0.05])\n",
    "\n",
    "# Step 1: Find the top 5 values and their indices\n",
    "topk_values, topk_indices = torch.topk(output_dist, k=5)\n",
    "\n",
    "# Step 2: Create a tensor with zeros and set the top 5 values\n",
    "filtered_dist = torch.zeros_like(output_dist)\n",
    "filtered_dist[topk_indices] = topk_values\n",
    "\n",
    "# Step 3: Normalize the filtered distribution to sum to 1\n",
    "scaled_dist = filtered_dist / filtered_dist.sum()\n",
    "\n",
    "print(\"Original distribution:\", output_dist)\n",
    "print(\"Filtered and scaled distribution:\", scaled_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0477c972-3aed-4a42-8946-09319bfe7f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
